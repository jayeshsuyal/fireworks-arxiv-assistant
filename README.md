# Fireworks arXiv Research Assistant

> **ğŸ“Š GTM Strategy: [Quick Read (90 sec)](gtm_quick.md) | [Full Analysis](gtm_notes.md)**

**A complete demonstration of fine-tuning progression: Baseline â†’ SFT â†’ RFT**

This project showcases measurable improvements through supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT) on a practical arXiv research assistant. Shows 26% improvement in relevance and 89% better citation accuracy for ~$15 total cost.

## ğŸ¯ What This Does

Compares three versions of an arXiv Q&A system:
1. **Baseline**: Llama-3.1-8B + RAG
2. **SFT**: Fine-tuned on 100 Q&A examples (~$3)
3. **RFT**: Preference-optimized on 50 pairs (~$5)

**Results:** 26% better relevance, 89% better citations, same latency/cost per query. Total pipeline cost: $15-20.

## ğŸš€ Quick Start

```bash
# 1. Setup
./setup.sh

# 2. Add API keys to .env
# FIREWORKS_API_KEY=your_key
# PINECONE_API_KEY=your_key
# PINECONE_ENVIRONMENT=us-east-1-aws

# 3. Run complete pipeline
bash run_pipeline.sh
```

Or run each step individually (see [Complete Workflow](#complete-workflow) below).

## ğŸ“ Project Structure

```
fireworks-arxiv-assistant/
â”‚
â”œâ”€â”€ 00_data_preparation/          # arXiv data pipeline
â”‚   â”œâ”€â”€ fetch_papers.py            # Fetch from arXiv API
â”‚   â”œâ”€â”€ embed_papers.py            # Store in Pinecone
â”‚   â”œâ”€â”€ generate_training_data.py  # Create 100 SFT examples
â”‚   â””â”€â”€ generate_preference_data.py # Create 50 RFT pairs
â”‚
â”œâ”€â”€ 01_baseline/                   # Baseline system
â”‚   â”œâ”€â”€ base_rag.py                # RAG with vanilla model
â”‚   â”œâ”€â”€ evaluate_base.py           # Measure baseline
â”‚   â””â”€â”€ test_queries.json          # 20 test questions
â”‚
â”œâ”€â”€ 02_sft_model/                  # Supervised Fine-Tuning
â”‚   â”œâ”€â”€ train_sft.py               # Train SFT model (~$3, 1hr)
â”‚   â”œâ”€â”€ sft_rag.py                 # RAG with SFT model
â”‚   â””â”€â”€ evaluate_sft.py            # Measure SFT accuracy
â”‚
â”œâ”€â”€ 03_rft_model/                  # Reinforcement Fine-Tuning
â”‚   â”œâ”€â”€ train_rft.py               # Train RFT model (~$5, 1hr)
â”‚   â”œâ”€â”€ rft_rag.py                 # RAG with RFT model
â”‚   â””â”€â”€ evaluate_rft.py            # Measure RFT accuracy
â”‚
â”œâ”€â”€ 04_comparison/                 # The GTM money shot
â”‚   â”œâ”€â”€ benchmark_all.py           # Compare all 3 models
â”‚   â”œâ”€â”€ visualize_results.py       # Generate charts
â”‚   â””â”€â”€ results.json               # Auto-generated metrics
â”‚
â”œâ”€â”€ 05_demo/                       # Customer demos
â”‚   â””â”€â”€ interactive_demo.py        # Live Q&A interface
â”‚
â””â”€â”€ utils/                         # Shared utilities
    â”œâ”€â”€ fireworks_client.py        # Fireworks API wrapper
    â”œâ”€â”€ pinecone_client.py         # Pinecone operations
    â””â”€â”€ metrics.py                 # Evaluation helpers
```

## ğŸ”„ Pipeline Steps

**1. Data Preparation** (~20 min, ~$5-8)
```bash
python 00_data_preparation/fetch_papers.py --max-results 100
python 00_data_preparation/embed_papers.py --provider fireworks
python 00_data_preparation/generate_training_data.py --num-examples 100
python 00_data_preparation/generate_preference_data.py --num-pairs 50
```

**2. Baseline** (~5 min, ~$0.50)
```bash
python 01_baseline/evaluate_base.py
```

**3. Train SFT** (~45 min, ~$3)
```bash
python 02_sft_model/train_sft.py train --training-file data/sft_training.jsonl --n-epochs 3
python 02_sft_model/evaluate_sft.py
```

**4. Train RFT** (~45 min, ~$5)
```bash
python 03_rft_model/train_rft.py --training-file data/rft_training.jsonl --n-epochs 3
python 03_rft_model/evaluate_rft.py
```

**5. Compare & Demo**
```bash
python 04_comparison/benchmark_all.py
python 04_comparison/visualize_results.py
python 05_demo/interactive_demo.py --mode interactive
```

## ğŸ“Š Results & Costs

**Performance Improvements:**
| Metric | Baseline | SFT | RFT | Î” |
|--------|----------|-----|-----|---|
| Relevance | 0.65 | 0.75 | 0.82 | +26% |
| Citation Accuracy | 45% | 70% | 85% | +89% |
| Latency | 1.8s | 1.9s | 1.85s | ~same |
| Cost/Query | $0.0025 | $0.0025 | $0.0025 | same |

**Total Pipeline Cost:** $15-20, ~2-3 hours

## âœ¨ Features

- **Data Pipeline:** Retry logic, rate limiting, deduplication, resume support, cost tracking
- **Training:** Automated upload, progress monitoring, background training, configurable hyperparameters
- **Evaluation:** Comprehensive metrics (relevance, latency, cost, citations), side-by-side comparison, visualizations
- **Demo:** Interactive CLI, model comparison, example queries

## ğŸ”§ Configuration

### API Keys (.env file)

```bash
# Required
FIREWORKS_API_KEY=your_fireworks_key
PINECONE_API_KEY=your_pinecone_key
PINECONE_ENVIRONMENT=us-east-1-aws
PINECONE_INDEX_NAME=arxiv-papers

# Optional (only if using OpenAI embeddings)
OPENAI_API_KEY=your_openai_key
```

Get API keys:
- Fireworks: https://fireworks.ai/
- Pinecone: https://www.pinecone.io/
- OpenAI: https://platform.openai.com/

### Customization

**Fetch more/fewer papers:**
```bash
python 00_data_preparation/fetch_papers.py --max-results 200
```

**Use different base model:**
```bash
python 02_sft_model/train_sft.py train \
  --base-model "accounts/fireworks/models/llama-v3p1-70b-instruct"
```

**Adjust training epochs:**
```bash
python 02_sft_model/train_sft.py train --n-epochs 5 --learning-rate 1e-5
```

**Change embedding provider:**
```bash
python 00_data_preparation/embed_papers.py --provider openai
```

## ğŸ“š Documentation

Detailed documentation for each module:
- [Data Preparation](00_data_preparation/README.md) - Complete data pipeline guide
- API Reference - See docstrings in each module

## ğŸ› Troubleshooting

- **Missing API Keys:** Add to `.env` file
- **Pinecone Index Not Found:** Auto-created on first `embed_papers.py` run
- **Model ID Not Found:** Train SFT before RFT
- **Out of Memory:** Shouldn't happen (training runs on Fireworks servers)

## ğŸ“„ License

MIT License

---

**Built to demonstrate measurable fine-tuning ROI with Fireworks AI**

For business strategy and market analysis, see [gtm_notes.md](gtm_notes.md)
